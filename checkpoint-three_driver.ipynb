{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
   },
   "source": [
    "# Checkpoint Three: Cleaning Data\n",
    "\n",
    "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
    "\n",
    "My datasets:\n",
    "- Conflict in Mexico: https://acleddata.com/data-export-tool/ (Armed Conflict Location & Event Data Project, January 1 2018 - December 31 2023, accessed October 18, 2024)\n",
    "- Forest over loss: https://www.globalforestwatch.org/dashboards/country/MEX/ (Global Forest Watch, 2001-2023, access October 11 2024)\n",
    "\n",
    "Import the necessary libraries and create your dataframe(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver</th>\n",
       "      <th>year</th>\n",
       "      <th>forest_loss_by_driver</th>\n",
       "      <th>gfw_gross_emissions_co2e_all_gases__Mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>2012</td>\n",
       "      <td>2988.479457</td>\n",
       "      <td>5.350261e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019</td>\n",
       "      <td>795.091102</td>\n",
       "      <td>1.991848e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commodity driven deforestation</td>\n",
       "      <td>2021</td>\n",
       "      <td>43255.446201</td>\n",
       "      <td>1.904717e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urbanization</td>\n",
       "      <td>2021</td>\n",
       "      <td>707.054035</td>\n",
       "      <td>3.712552e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>2011</td>\n",
       "      <td>2072.176484</td>\n",
       "      <td>2.844520e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           driver  year  forest_loss_by_driver  \\\n",
       "0                         Unknown  2012            2988.479457   \n",
       "1                         Unknown  2019             795.091102   \n",
       "2  Commodity driven deforestation  2021           43255.446201   \n",
       "3                    Urbanization  2021             707.054035   \n",
       "4                         Unknown  2011            2072.176484   \n",
       "\n",
       "   gfw_gross_emissions_co2e_all_gases__Mg  \n",
       "0                            5.350261e+05  \n",
       "1                            1.991848e+05  \n",
       "2                            1.904717e+07  \n",
       "3                            3.712552e+05  \n",
       "4                            2.844520e+05  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DRIVER GFW csv file into separate dataframes:\n",
    "driver_df = pd.read_csv('/Users/audreythill/Desktop/LaunchCode/Python/Final Project/eda-checkpoint/GFW_Mexico_treecover_loss__ha.csv')\n",
    "\n",
    "# Rename several columns to make them easier reference in EDA and to match the conflict_df: rename the 'umd_tree_cover_loss__year' to 'year'\n",
    "forest_renamed = driver_df.rename(columns={'umd_tree_cover_loss__year': 'year', 'adm1': 'admin1', 'tsc_tree_cover_loss_drivers__driver': 'driver', 'umd_tree_cover_loss__ha': 'forest_loss_by_driver'})\n",
    "\n",
    "forest_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
   },
   "source": [
    "## Missing Data\n",
    "\n",
    "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver                                    0\n",
      "year                                      0\n",
      "forest_loss_by_driver                     0\n",
      "gfw_gross_emissions_co2e_all_gases__Mg    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify how many nulls there are in the df:\n",
    "print(forest_renamed.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
   },
   "source": [
    "## Irregular Data\n",
    "\n",
    "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "azdata_cell_guid": "efed50ae-16f0-471d-98e2-632553a74c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max forest loss by driver: 244467.94 hectares\n",
      "min forest loss by driver: 183.03 hectares\n"
     ]
    }
   ],
   "source": [
    "# Find the max and minimum values for forest loss by driver (and round 2 decimal places):\n",
    "max_forest_loss_by_driver = forest_renamed['forest_loss_by_driver'].max().round(2)\n",
    "print(f\"max forest loss by driver: {max_forest_loss_by_driver} hectares\")\n",
    "\n",
    "min_forest_loss_by_driver =forest_renamed['forest_loss_by_driver'].min().round(2)\n",
    "print(f\"min forest loss by driver: {min_forest_loss_by_driver} hectares\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420.49\n",
      "43034.61\n",
      "41614.12\n"
     ]
    }
   ],
   "source": [
    "# Now I want to look at the 1st and 3rd quartiles and find the inner quartile range to get a better sense of the data spread.\n",
    "# For forest loss by driver:\n",
    "Q1_driver = forest_renamed['forest_loss_by_driver'].quantile(0.25).round(2)\n",
    "Q3_driver = forest_renamed['forest_loss_by_driver'].quantile(0.75).round(2)\n",
    "IQR_driver = Q3_driver - Q1_driver   # calculate the inter-quartile range\n",
    "print(Q1_driver)  \n",
    "print(Q3_driver)\n",
    "print(IQR_driver)\n",
    "\n",
    "\n",
    "# It's interesting to see that the IQR for these two columns are not the same. But this is to be expected since they represent different units of analysis (admin vs. driver).\n",
    "# The larger IQR for forest loss by driver suggests that there is more variability attributable to the different drivers of deforestation. \n",
    "# For example, Q3 is very high (59559.54 ha), meaning the data skews to the right. This suggests that while a significant portion of the data has relatively low forest loss\n",
    "# (up to Q1, which is 1451.35), there some drivers that lead to extremely high forest loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   driver  year  forest_loss_by_driver  \\\n",
      "70   Shifting agriculture  2019          244467.937745   \n",
      "74   Shifting agriculture  2011          134235.339909   \n",
      "75   Shifting agriculture  2005          152518.165832   \n",
      "76   Shifting agriculture  2002          119783.012726   \n",
      "78   Shifting agriculture  2003          107709.943029   \n",
      "87   Shifting agriculture  2007          161251.748375   \n",
      "90   Shifting agriculture  2023          140197.844185   \n",
      "91   Shifting agriculture  2016          202491.648488   \n",
      "94   Shifting agriculture  2018          192642.494869   \n",
      "97   Shifting agriculture  2006          119823.198893   \n",
      "99   Shifting agriculture  2008          131157.298720   \n",
      "101  Shifting agriculture  2015          138919.102405   \n",
      "104  Shifting agriculture  2021          126386.193787   \n",
      "106  Shifting agriculture  2004          125829.313461   \n",
      "107  Shifting agriculture  2020          214619.365181   \n",
      "108  Shifting agriculture  2009          192429.334132   \n",
      "117  Shifting agriculture  2012          120632.454339   \n",
      "127  Shifting agriculture  2013          148826.890126   \n",
      "130  Shifting agriculture  2022          125763.104298   \n",
      "132  Shifting agriculture  2001          116589.124458   \n",
      "133  Shifting agriculture  2010          125323.137957   \n",
      "134  Shifting agriculture  2017          209201.248195   \n",
      "137  Shifting agriculture  2014          128198.090734   \n",
      "\n",
      "     gfw_gross_emissions_co2e_all_gases__Mg  \n",
      "70                             1.185682e+08  \n",
      "74                             5.645216e+07  \n",
      "75                             5.578125e+07  \n",
      "76                             4.135932e+07  \n",
      "78                             3.698763e+07  \n",
      "87                             6.299583e+07  \n",
      "90                             7.207753e+07  \n",
      "91                             9.339380e+07  \n",
      "94                             9.141857e+07  \n",
      "97                             4.465103e+07  \n",
      "99                             5.142603e+07  \n",
      "101                            6.142927e+07  \n",
      "104                            6.390280e+07  \n",
      "106                            4.451436e+07  \n",
      "107                            1.030155e+08  \n",
      "108                            7.477077e+07  \n",
      "117                            5.125959e+07  \n",
      "127                            6.384138e+07  \n",
      "130                            6.986101e+07  \n",
      "132                            4.047012e+07  \n",
      "133                            5.155331e+07  \n",
      "134                            9.728554e+07  \n",
      "137                            5.608088e+07  \n"
     ]
    }
   ],
   "source": [
    "# # Now find the outliers by establishing boundaries based on adding or subtracting 1.5X the inter-quartile range (IQR)\n",
    "# by driver:\n",
    "lower_bound = Q1_driver - 1.5 * IQR_driver\n",
    "upper_bound = Q3_driver + 1.5 * IQR_driver\n",
    "outliers = forest_renamed[(forest_renamed['forest_loss_by_driver'] < lower_bound) | (forest_renamed['forest_loss_by_driver'] > upper_bound)]\n",
    "print(outliers)\n",
    "# I see the outliers for forest loss are heavily represented by ‘commodity driven deforestation’ and ‘shifting agriculture’ in the ‘driver’ column.\n",
    "# Based on my visualizations in EDA, I know these are important outliers to include."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
   },
   "source": [
    "## Unnecessary Data\n",
    "\n",
    "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['driver', 'year', 'forest_loss_by_driver',\n",
      "       'gfw_gross_emissions_co2e_all_gases__Mg'],\n",
      "      dtype='object')\n",
      "Index(['driver', 'year', 'forest_loss_by_driver'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# There is quite a bit of unnecessary data. I want to drop some columns, so first I will print out the current column names.\n",
    "print(forest_renamed.columns)\n",
    "\n",
    "# The following columns are not relevant to my research scope so I will drop them:\n",
    "#     - ACLED: 'inter1', 'inter2', 'interaction', 'civilian_targeting', 'iso_y', 'disorder_type', 'event_date', 'region', 'admin2', 'admin3', 'source', 'geo_precision', 'source_scale', 'country', 'location', 'notes', 'tags','timestamp’, 'time_precision'\n",
    "#     - GFW: 'gfw_gross_emissions_co2e_all_gases__Mg_driver', 'iso_x', 'gfw_gross_emissions_co2e_all_gases__Mg_admin'\n",
    "\n",
    "merged_df = forest_renamed.drop(columns=['gfw_gross_emissions_co2e_all_gases__Mg',\n",
    "                                            ])\n",
    "print(merged_df.columns)\n",
    "# I did leave in a few columns (from ACLED conflict dataset) that are not necessary to my immediate project but that might be \n",
    "# interesting to look at later. E.g, actor names and the types of violence.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to drop forest data prior to 2015 because this is when GFW changed their methodology. Comparing old and new data, especially before/after 2015\n",
    "# could result in inaccurate analysis.\n",
    "\n",
    "after_2015_merged_df = merged_df[merged_df['year'] >= 2015]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
   },
   "source": [
    "## Inconsistent Data\n",
    "\n",
    "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['driver', 'year', 'forest loss by driver'], dtype='object')\n",
      "                             driver  year  forest loss by driver\n",
      "1                           Unknown  2019             795.091102\n",
      "2    Commodity driven deforestation  2021           43255.446201\n",
      "3                      Urbanization  2021             707.054035\n",
      "7                      Urbanization  2015             862.337747\n",
      "8    Commodity driven deforestation  2017           76080.396553\n",
      "10                     Urbanization  2018            1014.596636\n",
      "12   Commodity driven deforestation  2020           72552.914783\n",
      "13                          Unknown  2018            1504.600186\n",
      "18   Commodity driven deforestation  2023           72558.881596\n",
      "19                          Unknown  2022            1070.804437\n",
      "20                     Urbanization  2023            1961.959394\n",
      "21                          Unknown  2017             699.846113\n",
      "22                     Urbanization  2017             563.918378\n",
      "23   Commodity driven deforestation  2022           40292.271384\n",
      "32                          Unknown  2023             183.033309\n",
      "37   Commodity driven deforestation  2019           68880.221063\n",
      "40                          Unknown  2016             732.079387\n",
      "41                     Urbanization  2016             625.927363\n",
      "44                          Unknown  2020             808.834756\n",
      "46   Commodity driven deforestation  2018           59559.544183\n",
      "47   Commodity driven deforestation  2015           49533.474180\n",
      "51                     Urbanization  2022             467.472364\n",
      "52   Commodity driven deforestation  2016           59370.245930\n",
      "53                          Unknown  2021            1457.583070\n",
      "55                          Unknown  2015             396.531300\n",
      "62                     Urbanization  2019             412.514117\n",
      "63                     Urbanization  2020             472.166498\n",
      "69                         Forestry  2021            5244.277730\n",
      "70             Shifting agriculture  2019          244467.937745\n",
      "71                         Forestry  2020            8862.894606\n",
      "81                         Wildfire  2017            2430.243492\n",
      "82                         Forestry  2017            9811.885329\n",
      "83                         Forestry  2015            7180.879549\n",
      "85                         Wildfire  2019            3102.661617\n",
      "86                         Forestry  2018            8105.461502\n",
      "90             Shifting agriculture  2023          140197.844185\n",
      "91             Shifting agriculture  2016          202491.648488\n",
      "93                         Wildfire  2023            4244.107779\n",
      "94             Shifting agriculture  2018          192642.494869\n",
      "96                         Wildfire  2022            5832.758350\n",
      "98                         Forestry  2016            9918.689914\n",
      "101            Shifting agriculture  2015          138919.102405\n",
      "103                        Forestry  2019            9779.357685\n",
      "104            Shifting agriculture  2021          126386.193787\n",
      "107            Shifting agriculture  2020          214619.365181\n",
      "120                        Wildfire  2016            1043.990979\n",
      "121                        Wildfire  2021           12028.864322\n",
      "122                        Wildfire  2015             758.555574\n",
      "124                        Forestry  2022            5431.468615\n",
      "129                        Forestry  2023            7205.221491\n",
      "130            Shifting agriculture  2022          125763.104298\n",
      "131                        Wildfire  2020            2210.113767\n",
      "134            Shifting agriculture  2017          209201.248195\n",
      "136                        Wildfire  2018            4324.023699\n"
     ]
    }
   ],
   "source": [
    "# I will rename some columns to be more descriptive to better facilitate my analysis in Tableau:\n",
    "after_2015_merged_df = after_2015_merged_df.rename(columns={\n",
    "       'even_id_cnty': 'conflict event',\n",
    "       'forest_loss_by_admin': 'forest loss by admin',\n",
    "       'forest_loss_by_driver': 'forest loss by driver',\n",
    "       'event_id_cnty': 'conflict event id',\n",
    "       'event_type': 'event type',\n",
    "       'sub_event_type': 'subevent type'       \n",
    "       })\n",
    "print(after_2015_merged_df.columns)\n",
    "print(after_2015_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Forest Loss By Driver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Forest Loss By Driver'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# First calculate the number of football field equivalents\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m after_2015_merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFootball Field Equivalents\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor((\u001b[43mafter_2015_merged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mForest Loss By Driver\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.4\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Repeat rows using NumPy\u001b[39;00m\n\u001b[1;32m      7\u001b[0m expanded_rows \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(df\u001b[38;5;241m.\u001b[39mvalues, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFootball Field Equivalents\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Forest Loss By Driver'"
     ]
    }
   ],
   "source": [
    "# Add a column for 'football field equilvalents' so i can make a bar chart with icons in Tableau.\n",
    "import numpy as np\n",
    "# First calculate the number of football field equivalents. np.floor ensures that the numbers round down so that I\n",
    "# don't end up with half of an icon.\n",
    "after_2015_merged_df['Football Field Equivalents'] = np.floor((after_2015_merged_df['Forest Loss By Driver'] * 1.4) / 1000).astype(int)\n",
    "\n",
    "# Repeat rows using NumPy so that each football equivalent has its own rows. \n",
    "expanded_rows = np.repeat(after_2015_merged_df.values, after_2015_merged_df['Football Field Equivalents'], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_2015_merged_df.to_csv('df_forest_loss_driver.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "dedc0bfe-17d0-40b2-914f-2ddb54f9ce0d"
   },
   "source": [
    "## Summarize Your Results\n",
    "\n",
    "Make note of your answers to the following questions.\n",
    "\n",
    "1. Did you find all four types of dirty data in your dataset?\n",
    "\n",
    "Yes, but these were not due to errors on the part of the people who created the dataset. They mostly stemmed from combining two separate datasets that used different spelling conventions for Mexican states. Additionally, there were null values, but these were not missing due to error but rather because there was not relevant data for those particular rows/columns (e.g., if a conflict event did not involve an 'associated actor 2'). I also dropped columns that are not relevant to my analysis and renamed columns so they are more descriptive. As for irregular data, I identified that there are indeed outliers, but based on what I saw, these are exactly what I will be looking for in my analysis.\n",
    "\n",
    "At first I thought I would drop the forest loss data that precedes January 2018 (when the conflict data starts), but then I realized I still may want to analyze general trends from those years. However, I did drop data prior to 2015 because this is when the GFW dataset creators changed their methodology.\n",
    "\n",
    "2. Did the process of cleaning your data give you new insights into your dataset?\n",
    "\n",
    "The process of identifying outliers in my forest loss data gave me some insights. For example, the IQR \n",
    "for 'forest loss by driver' was larger than 'forest loss by admin'. For 'driver', the 3rd quartile was quite high, meaning the data skewed significantly to the right -- this leads me to think that most drivers have little relationship to forest loss whereas a few drivers have a significant impact. On the other hand, the lower IQR for 'admin'-related forest loss suggests that the specific admin is less of a factor in teh forest loss.\n",
    "\n",
    "3. Is there anything you would like to make note of when it comes to manipulating the data and making visualizations?\n",
    "\n",
    "As described above, I will definitely need to drill into the relationship between admin and forest loss. Based on my calculations of IQR, it appears to be less of a factor compared to other 'drivers' of forest loss, but this does not mean there is not a statistical relationship. I will try to do a regression analysis in addition to other charts/graphs.\n",
    "\n",
    "I will also be interested to use the latitute and longituede (provided by the ACLED conflict dataset) to make maps. Hopefully this works to create shading on individual states.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
